---
title: "Convolutional Neural Network(CNN)"
date : 2025-12-14 00:00:00 +0900
categories: [DeepLearning, models,]
tags : [DeepLearning, CNN , Convolution , deep learning]
---


## Convolutional Neural Network(CNN)

CNN(합성공 신경망) 이란 딥러닝의 모델중 하나로 인간의 시신경 구조를 모방하여 만들어졌으며 이 모델은 합성곱(Convolution)과 풀링(Pooling) 연산을 반복적으로 적용하여 데이터의 불변하는 특징을 추출한다.

### Why Convolutinal?

#### 1, Parameter Problem in image Rescognition

기존 모델은 영상 인식에서 해상도에 따라 Input Node의 개수가 급증하는 문제가 있다.

ex : 1920 x 720 pixel => 1382400 input nodes
1382400개의 노드와 200개의 Hidden Layer 노드만 있어도 파라미터수는 276480000개가 된다.
276480000 개의 가중치를 업데이트한다면 계산량이 엄청나게 많아지고 Deep architecture 구현은 사실상 불가능하다.

#### 2, Solution : Weight Sharing 

해결책으로 상세한 하나의 노드마다 가중치가 아닌 한 필터를 설정해 이 값을 고정해 전체 이미지 영역에 적용 시킨다.

![CNN](/assets/img/posts/deep_learning_cnn/1.png)

이렇게 하면 파라미터수를 획기적으로 줄일수있다.
ex : 100filter with 10x10 => only 10000parameters

#### 3, What is "convolution"?

Convolution = Inner Product(내적) + Sliding

Inner Product = 필터와 Input Layer 영역간의 element-wise 곱셈후 연산
Sliding = 필터를 일정 간경(stride)으로 이동하며 연산을 반복

Filter를 활용한 얼굴 인식 예시:
* input : 군중 이미지
* filter : 얼굴 형태를 나타나는 패턴 (코위치 눈위치등 일반적인 사람의 얼굴의 특징)
* Operation : 필터를 이미지 전체에 sliding하며 얼굴위치를 탐지
* output : 얼굴이 있는 위치에서 높은 activation 값

![CNN](/assets/img/posts/deep_learning_cnn/2.png)


### Overall architecture of CNN

CNN은 여러 단계의 convolution을 조합한 구조이다.

![CNN](/assets/img/posts/deep_learning_cnn/3.png)

3차원 텐서의 구조로
* Width (w) : 이미지 가로 크기
* Height (h) : 이미지 세로 크기
* Depth (D) or channel : 색상 채널 수 또는 feature map 수

ex : 
input size 32x32x3 (RGB channels)
using 12 filters -> Output : 32x32x12
Final output : 1x1x10(10 classes)

![CNN](/assets/img/posts/deep_learning_cnn/4.png)

#### Main components of CNN

CNN은 세가지 핵심 구성요소로 이루어진다.
* Convolutional Layers : Feature extraction
* Pooling Layers : Downsampling and dimension reduction
* Fully - Connected Layers : Final classification


#### Example Architecture : CIFAR-10 Classification

Input : [32x32x3] : height * width * channels(RGB)
Convolutional Layer : if 12filters used -> Output : [32x32x12]
ReLU : Select maximum using max(0, feature value) -> Output[32x32x12]
Pooling : Downsampling(e.g, 2*2) -> Output [16x16x12]
FC layer :  compute the scores [1x1x10]


### Convolution Layer : Detail procedure

3개의 hyper-parameters가 output의 크기를 정한다
* Depth : number of filter(필터의 개수)
* Stride : interval of moving of a filter(몇 픽셀 단위로 Sliding 할지)
* Zero-padding : control of the outputsize

Outputsize의 공식.

    (W-F+2P)/S +1

    W : input size(width or height)
    F : Filter size(receptive field)
    S : Stride value(통상적으로 1로 사용)
    P : Amount of zero padding


1차원 데이터로 계산예시

![CNN](/assets/img/posts/deep_learning_cnn/6.png)

#### why use zero-padding

예를 들어 이미지의 데이터가 5x5 filter가 3*3 이라고 가정하면(Depth는 편의상 1) 데이터는 

0 3 2 3 4 
1 2 3 2 2       -1 0 1
2 2 2 1 4   x    1 1 0   
5 1 0 0 2        0 0 1
0 2 5 2 4

이런식으로 있다.
여기서 가장자리의 데이터들을 계산할때 크기를 맞춰줘야하는데 현재 예시 데이터에서 가장 왼쪽위의 0 데이터에 맞춰주기에는 필터데이터의  가로 -1 0 1 세로 -1 1 0 의 데이터에 해당하는 값이 없다.

그래서 출력의 크기를 맞춰주기위해 (일반적으로 0)의 데이터를 채워넣는것을 padding이라고 한다.


#### Constraints on strides

stride의 값은 output의 크기가 정수로 나오도록 해야한다.
ex : w=10 , F=3 , P=0 , S=2?
output size => 7/2 = 3.5 XXXXXXXXXX NOT INTERGER!!


#### Alexnet for image classification

![CNN](/assets/img/posts/deep_learning_cnn/7.png)



#### parameter (weight) sharing

* Fundamental Principle:
  
하나의 feature가 유용하다면 모든 부분의 계산에 똑같은 특징을 계산한다


* Conv layer가 55x55x96의 크기로 290,400개의 뉴런과 11x11x3=363의 weight가 있다고 해보자.

총 파라미터의 수는 294000*(363+1(bias))의 크기가 된다.

to reduce parameters? -> weight sharing

![CNN](/assets/img/posts/deep_learning_cnn/8.png)


#### summarize the Conv layer

핵심 아이디어는 filter(weight)값의 공유.

![CNN](/assets/img/posts/deep_learning_cnn/9.png)

![CNN](/assets/img/posts/deep_learning_cnn/10.png)

### Poling Layer

Poling Layer purpose
* Reduction of parameters - 전체 파라미터와 연산량을 줄여 계산부담을 줄임
* Control overfitting - 모델이 특정 위치나 세부 노이즈에 과적합되는것을 방지
* invariance to small translations - 동일한 특징이 이미지 내 작은 위치 이동에도 동일하게 인식되도록하며 위치에 따른 민감도를 줄여 일반화 성능 향상.

Most common : MAX pooling selects the maximum values from each region
통상적으로 2x2크기(stride 2)안에서 가장 큰 값을 뽑아 뽑혀진 수로 다시 재구성.

![CNN](/assets/img/posts/deep_learning_cnn/11.png)

### Fuly-Connected (FC) Layers


FC Layers purpose

FC Layer는 마지막에 위치해 최종 분류를 담당하는 경우가 많다.

* Representative architecture of traditional neural networks - 전통적인 신경망의 대표적인 아키텍처
* Can be computed by matrix operations - 행렬 연산으로 계산될수있다. 효율적으로 벡터화된 선형변환으로 계산된다.
* Usually placed at the end of CNN for final classification


Conv Layer와 Poling Layer를 거쳐서 추출된 데이터를 1차원 벡터로 쭉 펼친뒤 하나의 fc layer를 두어 클래스 예측에 사용된다.

